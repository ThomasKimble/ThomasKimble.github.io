I"g<p>We used computer vision to detect and track two seperate Thymios, and switch their positions using following an optimal path, all while avoiding local obstacles.</p>

<ul>
  <li><strong>Date:</strong> December 2019</li>
  <li><strong>Author:</strong> Thomas Kimble, Raphael Ausilio, Valentin Karam, Niccol√≤ Stefanini</li>
  <li><strong>Field of Study:</strong> Robotics, Navigation, Path Planning, Computer Vision, Filtering</li>
  <li><strong>Context:</strong> EPFL Ma-1 <em>Mobile Robotics</em> Project</li>
</ul>

<div class="web-image-md">
    <img src="../../images/project-images/thymio/thymio_robot.png" />
</div>

<h1 id="goal">Goal</h1>

<p>We had a lot of freedom in the creation of this project, with our only instructions being to use the <em>Thymio</em> robot and to create a project that included the following four concepts:</p>
<ul>
  <li><strong>vision</strong></li>
  <li><strong>global navigation</strong></li>
  <li><strong>local navigation</strong></li>
  <li><strong>filtering</strong></li>
</ul>

<p>We decided to use two <em>thymio</em> robots in flat arena with stationary global obstacles. The goal was to switch their positions using an optimal path planning algorithm around the global map. Local obstacles were allowed to be introduced into the arena at any moment so we used a collision avoidance algorithm to contour each local obstacle. We used a Kalman filter for position state estimation and correction, using odometry and camera data.</p>

<h1 id="vision">Vision</h1>

<p>We used an external webcam to take a birds eye image of our global map containing the global obstacles and the two Thymios:</p>

<div class="web-image-md">
    <img src="../../images/project-images/thymio/thymio_global_map.png" />
</div>

<p>Every time step we take a picture of the global map and filter the image. We use morphological operators that recognize a 3D printed part place on the robot to estimate it‚Äôs position and orientation. These operators also detect the global obstacles as shown in the image below. From this we can extract an occupancy grid with the pose of each <em>thymio</em> and obstacle.</p>

<div class="web-image-md">
    <img src="../../images/project-images/thymio/thymio_detection.png" />
</div>

<h1 id="global-navigation">Global Navigation</h1>

<p>We chose the A* search algorithm thanks to its completeness, optimality, and efficiency. Since the two robots are to switch positions, their optimal paths should theoretically be identical. Therefore we calculate the trajectory for one robot, and consider it to be an obstacle in it‚Äôs ‚Äúhalf way‚Äù position during the calculations for the second robot.</p>

<p>This gives us a different path for each robot</p>
<div class="web-image-md">
    <img src="../../images/project-images/thymio/thymio_paths.png" />
</div>

<p>Here we create the different parameters we are going to use for navigation:</p>
<ul>
  <li><strong>posArray</strong>: an array of global path positions [ [x y orientation] ‚Ä¶ [x y orientation] ]</li>
  <li><strong>movArray</strong>: an array of movements for the global path [ [dx dy] ‚Ä¶ [dx dy] ]</li>
  <li><strong>dirArray</strong>: an array of next directions (relative to the robot‚Äôs current position) for the global path [d d ‚Ä¶ d]</li>
</ul>

<p>The orientation and next directions are defined as follows:</p>

<div class="web-image-md">
    <img src="../../images/project-images/thymio/thymio_movement.svg" />
</div>

<h1 id="local-navigation">Local Navigation</h1>

<h1 id="filtering">Filtering</h1>

<h1 id="additional-material">Additional Material</h1>

<p>For any more information on the project, please don‚Äôt hesitate to contact me <a href="/contact">here</a>, or check out the jupyter notebook below.</p>

<div class="row justify-content-center">
  <div class="col-auto">
    <a class="button_link" href="https://github.com/ThomasKimble/thymio-mobile-robotics" target="_blank">Code</a>
  </div>
</div>
:ET